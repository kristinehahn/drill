---
title: "Planning and Execution Options"
parent: "Configuration Options"
---
You can set Drill query planning and execution options per cluster, at the
system or session level. Options set at the session level only apply to
queries that you run during the current Drill connection. Options set at the
system level affect the entire system and persist between restarts. Session
level settings override system level settings.

#### Querying Planning and Execution Options

You can run the following query to see a list of the system and session
planning and execution options:

    SELECT name FROM sys.options WHERE type in ('SYSTEM','SESSION');

#### Configuring Planning and Execution Options

Use the` ALTER SYSTEM` or `ALTER SESSION` commands to set options. Typically,
you set the options at the session level unless you want the setting to
persist across all sessions.

The following table contains planning and execution options that you can set
at the system or session level:

<div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh">Option name</th><th class="confluenceTh">Default value</th><th class="confluenceTh">Description</th></tr><tr><td valign="top" colspan="1" class="confluenceTd">exec.errors.verbose</td><td valign="top" colspan="1" class="confluenceTd"><p>false</p></td><td valign="top" colspan="1" class="confluenceTd"><p>This option enables or disables the verbose message that Drill returns when a query fails. When enabled, Drill provides additional information about failed queries.</p></td></tr><tr><td valign="top" colspan="1" class="confluenceTd"><span>exec.max_hash_table_size</span></td><td valign="top" colspan="1" class="confluenceTd">1073741824</td><td valign="top" colspan="1" class="confluenceTd"><span>The default maximum size for hash tables.</span></td></tr><tr><td valign="top" colspan="1" class="confluenceTd">exec.min_hash_table_size</td><td valign="top" colspan="1" class="confluenceTd">65536</td><td valign="top" colspan="1" class="confluenceTd">The default starting size for hash tables. Increasing this size is useful for very large aggregations or joins when you have large amounts of memory for Drill to use. Drill can spend a lot of time resizing the hash table as it finds new data. If you have large data sets, you can increase this hash table size to increase performance.</td></tr><tr><td valign="top" colspan="1" class="confluenceTd">planner.add_producer_consumer</td><td valign="top" colspan="1" class="confluenceTd"><p>false</p><p> </p></td><td valign="top" colspan="1" class="confluenceTd"><p>This option enables or disables a secondary reading thread that works out of band of the rest of the scanning fragment to prefetch data from disk. <span style="line-height: 1.4285715;background-color: transparent;">If you interact with a certain type of storage medium that is slow or does not prefetch much data, this option tells Drill to add a producer consumer reading thread to the operation. Drill can then assign one thread that focuses on a single reading fragment. </span></p><p>If Drill is using memory, you can disable this option to get better performance. If Drill is using disk space, you should enable this option and set a reasonable queue size for the planner.producer_consumer_queue_size option.</p></td></tr><tr><td valign="top" colspan="1" class="confluenceTd">planner.broadcast_threshold</td><td valign="top" colspan="1" class="confluenceTd">1000000</td><td valign="top" colspan="1" class="confluenceTd"><span style="color: rgb(34,34,34);">Threshold, in terms of a number of rows, that determines whether a broadcast join is chosen for a query. Regardless of the setting of the broadcast_join option (enabled or disabled), a broadcast join is not chosen unless the right side of the join is estimated to contain fewer rows than this threshold. The intent of this option is to avoid broadcasting too many rows for join purposes. Broadcasting involves sending data across nodes and is a network-intensive operation. (The &quot;right side&quot; of the join, which may itself be a join or simply a table, is determined by cost-based optimizations and heuristics during physical planning.)</span></td></tr><tr><td valign="top" colspan="1" class="confluenceTd"><p>planner.enable_broadcast_join<br />planner.enable_hashagg<br />planner.enable_hashjoin<br />planner.enable_mergejoin<br />planner.enable_multiphase_agg<br />planner.enable_streamagg</p></td><td valign="top" colspan="1" class="confluenceTd">true</td><td valign="top" colspan="1" class="confluenceTd"><p>These options enable or disable specific aggregation and join operators for queries. These operators are all enabled by default and in general should not be disabled.</p><p>Hash aggregation and hash join are hash-based operations. Streaming aggregation and merge join are sort-based operations. Both hash-based and sort-based operations consume memory; however, currently, hash-based operations do not spill to disk as needed, but the sort-based operations do. If large hash operations do not fit in memory on your system, you may need to disable these operations. Queries will continue to run, using alternative plans.</p></td></tr><tr><td valign="top" colspan="1" class="confluenceTd">planner.producer_consumer_queue_size</td><td valign="top" colspan="1" class="confluenceTd">10</td><td valign="top" colspan="1" class="confluenceTd">Determines how much data to prefetch from disk (in record batches) out of band of query execution. The larger the queue size, the greater the amount of memory that the queue and overall query execution consumes.</td></tr><tr><td valign="top" colspan="1" class="confluenceTd">planner.slice_target</td><td valign="top" colspan="1" class="confluenceTd">100000</td><td valign="top" colspan="1" class="confluenceTd">The number of records manipulated within a fragment before Drill parallelizes them.</td></tr><tr><td valign="top" colspan="1" class="confluenceTd"><p>planner.width.max_per_node</p><p> </p></td><td valign="top" colspan="1" class="confluenceTd"><p>The default depends on the number of cores on each node.</p></td><td valign="top" colspan="1" class="confluenceTd"><p>In this context &quot;width&quot; refers to fanout or distribution potential: the ability to run a query in parallel across the cores on a node and the nodes on a cluster.</p><p><span>A physical plan consists of intermediate operations, known as query &quot;fragments,&quot; that run concurrently, yielding opportunities for parallelism above and below each exchange operator in the plan. An exchange operator represents a breakpoint in the execution flow where processing can be distributed. For example, a single-process scan of a file may flow into an exchange operator, followed by a multi-process aggregation fragment.</span><span> </span></p><p>The maximum width per node defines the maximum degree of parallelism for any fragment of a query, but the setting applies at the level of a single node in the cluster.</p><p>The <em>default</em> maximum degree of parallelism per node is calculated as follows, with the theoretical maximum automatically scaled back (and rounded down) so that only 70% of the actual available capacity is taken into account:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<script type="syntaxhighlighter" class="theme: Default; brush: java; gutter: false"><![CDATA[number of active drillbits (typically one per node) 
* number of cores per node
* 0.7]]></script>
</div></div><p>For example, on a single-node test system with 2 cores and hyper-threading enabled:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<script type="syntaxhighlighter" class="theme: Default; brush: java; gutter: false"><![CDATA[1 * 4 * 0.7 = 3]]></script>
</div></div><p>When you modify the default setting, you can supply any meaningful number. The system does not automatically scale down your setting.</p></td></tr><tr><td valign="top" colspan="1" class="confluenceTd">planner.width.max_per_query</td><td valign="top" colspan="1" class="confluenceTd">1000</td><td valign="top" colspan="1" class="confluenceTd"><p>The max_per_query value also sets the maximum degree of parallelism for any given stage of a query, but the setting applies to the query as executed by the whole cluster (multiple nodes). In effect, the actual maximum width per query is the <em>minimum of two values</em>:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<script type="syntaxhighlighter" class="theme: Default; brush: java; gutter: false"><![CDATA[min((number of nodes * width.max_per_node), width.max_per_query)]]></script>
</div></div><p>For example, on a 4-node cluster where <span><code>width.max_per_node</code> is set to 6 and </span><span><code>width.max_per_query</code> is set to 30:</span></p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<script type="syntaxhighlighter" class="theme: Default; brush: java; gutter: false"><![CDATA[min((4 * 6), 30) = 24]]></script>
</div></div><p>In this case, the effective maximum width per query is 24, not 30.</p></td></tr><tr><td valign="top" colspan="1" class="confluenceTd">store.format</td><td valign="top" colspan="1" class="confluenceTd"> </td><td valign="top" colspan="1" class="confluenceTd">Output format for data that is written to tables with the CREATE TABLE AS (CTAS) command.</td></tr><tr><td valign="top" colspan="1" class="confluenceTd">store.json.all_text_mode</td><td valign="top" colspan="1" class="confluenceTd"><p>false</p></td><td valign="top" colspan="1" class="confluenceTd"><p>This option enables or disables text mode. When enabled, Drill reads everything in JSON as a text object instead of trying to interpret data types. This allows complicated JSON to be read using CASE and CAST.</p></td></tr><tr><td valign="top" class="confluenceTd">store.parquet.block-size</td><td valign="top" class="confluenceTd"><p>536870912</p></td><td valign="top" class="confluenceTd">T<span style="color: rgb(34,34,34);">arget size for a parquet row group, which should be equal to or less than the configured HDFS block size. </span></td></tr></tbody></table></div>